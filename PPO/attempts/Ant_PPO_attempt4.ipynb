{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install gymnasium[mujoco]\n","!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LzpYjqmZU3lf","outputId":"a4e78818-bd81-4f72-a3ea-63b7d6fe204d","executionInfo":{"status":"ok","timestamp":1717828240499,"user_tz":-540,"elapsed":67741,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium[mujoco]\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (4.12.1)\n","Collecting farama-notifications>=0.0.1 (from gymnasium[mujoco])\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Collecting mujoco>=2.3.3 (from gymnasium[mujoco])\n","  Downloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.31.6)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (9.4.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.4.0)\n","Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.7.0)\n","Collecting glfw (from mujoco>=2.3.3->gymnasium[mujoco])\n","  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (3.1.7)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (6.4.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (3.19.1)\n","Installing collected packages: glfw, farama-notifications, gymnasium, mujoco\n","Successfully installed farama-notifications-0.0.4 glfw-2.7.0 gymnasium-0.29.1 mujoco-3.1.6\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"U7UQ5GajUueB","executionInfo":{"status":"ok","timestamp":1717828615391,"user_tz":-540,"elapsed":10,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"outputs":[],"source":["import gymnasium as gym\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.distributions import MultivariateNormal\n","\n","import sys\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["# 모델 정의\n","class PolicyNetwork(nn.Module):\n","    def __init__(self, obs_dim, action_dim):\n","        super(PolicyNetwork, self).__init__()\n","        self.fc1 = nn.Linear(obs_dim, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc_mean = nn.Linear(64, action_dim)\n","        self.fc_log_std = nn.Linear(64, action_dim)\n","        self.to(device)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        mean = self.fc_mean(x)\n","        log_std = self.fc_log_std(x)\n","        return mean, log_std\n","\n","class ValueNetwork(nn.Module):\n","    def __init__(self, obs_dim):\n","        super(ValueNetwork, self).__init__()\n","        self.fc1 = nn.Linear(obs_dim, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc_value = nn.Linear(64, 1)\n","        self.to(device)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        value = self.fc_value(x)\n","        return value"],"metadata":{"id":"Zv-aRyevU51p","executionInfo":{"status":"ok","timestamp":1717828615393,"user_tz":-540,"elapsed":9,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 가우시안 분포 생성 함수\n","def get_action_and_log_prob(state, policy):\n","    mean, log_std = policy(state)\n","    std = log_std.exp()\n","    dist = MultivariateNormal(mean, torch.diag_embed(std))\n","    action = dist.sample()\n","    log_prob = dist.log_prob(action)\n","    return action, log_prob"],"metadata":{"id":"YLGz02dNVBvN","executionInfo":{"status":"ok","timestamp":1717828618970,"user_tz":-540,"elapsed":11,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# PPO 업데이트 함수\n","def ppo_update(policy, value_net, optimizer_policy, optimizer_value, states, actions, rewards, old_log_probs, advantages):\n","    for _ in range(K_epochs):\n","        mean, log_std = policy(states)\n","        std = log_std.exp()\n","        dist = MultivariateNormal(mean, torch.diag_embed(std))\n","        new_log_probs = dist.log_prob(actions)\n","        ratio = (new_log_probs - old_log_probs).exp()\n","\n","        surrogate1 = ratio * advantages\n","        surrogate2 = torch.clamp(ratio, 1 - epsilon_clip, 1 + epsilon_clip) * advantages\n","\n","        policy_loss = -torch.min(surrogate1, surrogate2).mean()\n","\n","        # Value loss\n","        values = value_net(states).squeeze()\n","        value_loss = ((values - rewards) ** 2).mean()\n","\n","        optimizer_policy.zero_grad()\n","        policy_loss.backward()\n","        optimizer_policy.step()\n","\n","        optimizer_value.zero_grad()\n","        value_loss.backward()\n","        optimizer_value.step()"],"metadata":{"id":"SB2QNr59VBxj","executionInfo":{"status":"ok","timestamp":1717828618971,"user_tz":-540,"elapsed":10,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 환경 설정\n","env = gym.make('Ant-v4')\n","obs_dim = env.observation_space.shape[0]\n","action_dim = env.action_space.shape[0]"],"metadata":{"id":"TxBy3ARhU539","executionInfo":{"status":"ok","timestamp":1717831023162,"user_tz":-540,"elapsed":5,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터 설정\n","learning_rate = 3e-4\n","gamma = 0.99\n","epsilon_clip = 0.2\n","K_epochs = 10\n","T_horizon = 2048"],"metadata":{"id":"-mdAZl4GU5zZ","executionInfo":{"status":"ok","timestamp":1717828621506,"user_tz":-540,"elapsed":10,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# 모델 초기화 및 옵티마이저 설정\n","policy = PolicyNetwork(obs_dim, action_dim).to(device)\n","value_net = ValueNetwork(obs_dim).to(device)\n","optimizer_policy = optim.Adam(policy.parameters(), lr=learning_rate)\n","optimizer_value = optim.Adam(value_net.parameters(), lr=learning_rate)"],"metadata":{"id":"6AJPexrvU5pr","executionInfo":{"status":"ok","timestamp":1717828622489,"user_tz":-540,"elapsed":7,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 메인 학습 루프\n","for episode in range(1000):\n","    state, _ = env.reset()\n","    terminated, truncated = False, False\n","    rewards = []\n","    log_probs = []\n","    states = []\n","    actions = []\n","    values = []\n","    episode_reward = 0\n","\n","    for t in range(T_horizon):\n","        state = torch.tensor(state, dtype=torch.float32).to(device)\n","        action, log_prob = get_action_and_log_prob(state, policy)\n","        value = value_net(state)\n","\n","        next_state, reward, terminated, truncated, _ = env.step(action.cpu().detach().numpy())\n","\n","        states.append(state)\n","        actions.append(action)\n","        rewards.append(reward)\n","        log_probs.append(log_prob)\n","        values.append(value)\n","\n","        state = next_state\n","        episode_reward += reward\n","\n","        if terminated or truncated:\n","            break\n","\n","    # Advantage 및 Discounted Rewards 계산\n","    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n","    values = torch.stack(values).squeeze().detach()\n","    discounted_rewards = []\n","    G = 0\n","    for reward in reversed(rewards):\n","        G = reward + gamma * G\n","        discounted_rewards.insert(0, G)\n","    discounted_rewards = torch.tensor(discounted_rewards, dtype=torch.float32).to(device)\n","    advantages = discounted_rewards - values\n","\n","    # Advantage 정규화\n","    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n","\n","    # PPO 업데이트\n","    states = torch.stack(states)\n","    actions = torch.stack(actions)\n","    old_log_probs = torch.stack(log_probs).detach()\n","    ppo_update(policy, value_net, optimizer_policy, optimizer_value, states, actions, discounted_rewards, old_log_probs, advantages)\n","\n","    if episode % 10 == 0:\n","        print(f\"Episode {episode}: Reward {episode_reward}\")\n","\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"collapsed":true,"id":"zUCQt5m0VCYl","outputId":"c763fe57-fe7f-4f0b-ba3a-7ac81307f803","executionInfo":{"status":"error","timestamp":1717831195498,"user_tz":-540,"elapsed":130631,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0: Reward 641.9183357919492\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/monitoring/video_recorder.py:178: UserWarning: \u001b[33mWARN: Unable to save last video! Did you call close()?\u001b[0m\n","  logger.warn(\"Unable to save last video! Did you call close()?\")\n"]},{"output_type":"stream","name":"stdout","text":["Episode 10: Reward 692.5380592047582\n","Episode 20: Reward 771.1388686969024\n","Episode 30: Reward 786.9480332789469\n","Episode 40: Reward 781.4883237282395\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7aaa158e1282>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_horizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action_and_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import os\n","\n","os.environ['MUJOCO_GL']='egl'"],"metadata":{"id":"-oBlh-Y8VCdk","executionInfo":{"status":"ok","timestamp":1717830548999,"user_tz":-540,"elapsed":5,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["env = gym.make('Ant-v4', render_mode='rgb_array')\n","env = gym.wrappers.RecordVideo(env, video_folder='./videos')"],"metadata":{"id":"KnfDLqs9VCgF","executionInfo":{"status":"ok","timestamp":1717830549719,"user_tz":-540,"elapsed":8,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["s, _ = env.reset()\n","terminated, truncated = False, False\n","while not (terminated or truncated):\n","    s = torch.tensor(s, dtype=torch.float32).to(device)\n","    a, _ = get_action_and_log_prob(s, policy)\n","    s, r, terminated, truncated, _ = env.step(a.cpu().detach().numpy())\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yEYnurWVCh7","outputId":"c19627a3-3326-45c6-daf6-513d4d2b6bb9","executionInfo":{"status":"ok","timestamp":1717830584670,"user_tz":-540,"elapsed":33003,"user":{"displayName":"이건영","userId":"04018543955246161192"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video /content/videos/rl-video-episode-0.mp4.\n","Moviepy - Writing video /content/videos/rl-video-episode-0.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready /content/videos/rl-video-episode-0.mp4\n"]}]}]}