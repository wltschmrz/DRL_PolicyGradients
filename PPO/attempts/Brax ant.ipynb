{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyNajAcKs9n6zHNtTOG/nGqW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install brax jax jaxlib flax optax"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bf7GFQ0-xOH2","executionInfo":{"status":"ok","timestamp":1715835885310,"user_tz":-540,"elapsed":11006,"user":{"displayName":"이건영","userId":"04018543955246161192"}},"outputId":"02e7c5ca-1e5f-4c86-d88d-4ba5b9e82716"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting brax\n","  Downloading brax-0.10.4-py3-none-any.whl (998 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m998.3/998.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.8.3)\n","Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from brax) (1.4.0)\n","Collecting dm-env (from brax)\n","  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n","Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from brax) (1.7.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from brax) (2.2.5)\n","Collecting flask-cors (from brax)\n","  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from brax) (1.63.0)\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from brax) (0.25.2)\n","Collecting jaxopt (from brax)\n","  Downloading jaxopt-0.8.3-py3-none-any.whl (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from brax) (3.1.4)\n","Collecting ml-collections (from brax)\n","  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mujoco (from brax)\n","  Downloading mujoco-3.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mujoco-mjx (from brax)\n","  Downloading mujoco_mjx-3.1.5-py3-none-any.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from brax) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from brax) (9.4.0)\n","Collecting pytinyrenderer (from brax)\n","  Downloading pytinyrenderer-0.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from brax) (1.11.4)\n","Collecting tensorboardX (from brax)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trimesh (from brax)\n","  Downloading trimesh-4.3.2-py3-none-any.whl (693 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.9/693.9 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from brax) (4.11.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.8)\n","Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.4)\n","Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.45)\n","Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.7.1)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.1)\n","Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.86)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax) (0.12.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-env->brax) (0.1.8)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->brax) (3.0.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->brax) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->brax) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->brax) (2.1.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->brax) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->brax) (0.0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections->brax) (1.16.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->brax) (21.6.0)\n","Collecting glfw (from mujoco->brax)\n","  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco->brax) (3.1.7)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->brax) (24.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils->brax) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils->brax) (6.4.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils->brax) (3.18.1)\n","Building wheels for collected packages: ml-collections\n","  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=2e1d8407b84016092dd522258bd2631575f906fa7874297f478f265e57880820\n","  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n","Successfully built ml-collections\n","Installing collected packages: pytinyrenderer, glfw, trimesh, tensorboardX, ml-collections, dm-env, mujoco, jaxopt, flask-cors, mujoco-mjx, brax\n","Successfully installed brax-0.10.4 dm-env-1.6 flask-cors-4.0.1 glfw-2.7.0 jaxopt-0.8.3 ml-collections-0.1.1 mujoco-3.1.5 mujoco-mjx-3.1.5 pytinyrenderer-0.0.14 tensorboardX-2.6.2.2 trimesh-4.3.2\n"]}]},{"cell_type":"code","source":["import jax\n","import jax.numpy as jnp\n","import numpy as np\n","import optax\n","from flax import linen as nn\n","from collections import deque\n","from IPython.display import HTML\n","import brax\n","from brax.io import html\n","from brax.envs import create\n","\n","# GPU 사용 확인\n","print(\"JAX Devices:\", jax.devices())\n","\n","# 병렬 환경 설정\n","def create_env(env_name, batch_size):\n","    env = create(env_name)\n","    reset_fn = jax.vmap(env.reset)\n","    step_fn = jax.vmap(env.step)\n","    return env, reset_fn, step_fn\n","\n","# Actor-Critic 네트워크 정의\n","class Actor(nn.Module):\n","    action_dim: int\n","\n","    @nn.compact\n","    def __call__(self, x):\n","        x = nn.Dense(128)(x)\n","        x = nn.relu(x)\n","        x = nn.Dense(128)(x)\n","        x = nn.relu(x)\n","        x = nn.Dense(self.action_dim)(x)\n","        x = nn.tanh(x)\n","        return x\n","\n","class Critic(nn.Module):\n","    @nn.compact\n","    def __call__(self, x, a):\n","        x = jnp.concatenate([x, a], axis=-1)\n","        x = nn.Dense(128)(x)\n","        x = nn.relu(x)\n","        x = nn.Dense(128)(x)\n","        x = nn.relu(x)\n","        x = nn.Dense(1)(x)\n","        return x\n","\n","# Replay Buffer 정의\n","class ReplayBuffer:\n","    def __init__(self, buffer_size, state_dim, action_dim):\n","        self.buffer = deque(maxlen=buffer_size)\n","        self.state_dim = state_dim\n","        self.action_dim = action_dim\n","\n","    def add(self, state, action, reward, next_state, done):\n","        self.buffer.append((state, action, reward, next_state, done))\n","\n","    def sample(self, batch_size):\n","        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n","        states, actions, rewards, next_states, dones = zip(*[self.buffer[idx] for idx in indices])\n","        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","# DDPG 알고리즘 정의\n","class DDPGAgent:\n","    def __init__(self, state_dim, action_dim, actor_lr, critic_lr, gamma, tau, buffer_size, batch_size):\n","        self.state_dim = state_dim\n","        self.action_dim = action_dim\n","        self.gamma = gamma\n","        self.tau = tau\n","        self.batch_size = batch_size\n","\n","        self.actor = Actor(action_dim)\n","        self.critic = Critic()\n","        self.target_actor = Actor(action_dim)\n","        self.target_critic = Critic()\n","\n","        self.actor_params = self.actor.init(jax.random.PRNGKey(0), jnp.ones((state_dim,)))\n","        self.critic_params = self.critic.init(jax.random.PRNGKey(1), jnp.ones((state_dim,)), jnp.ones((action_dim,)))\n","        self.target_actor_params = self.actor_params\n","        self.target_critic_params = self.critic_params\n","\n","        self.actor_optimizer = optax.adam(actor_lr)\n","        self.critic_optimizer = optax.adam(critic_lr)\n","        self.actor_opt_state = self.actor_optimizer.init(self.actor_params)\n","        self.critic_opt_state = self.critic_optimizer.init(self.critic_params)\n","\n","        self.replay_buffer = ReplayBuffer(buffer_size, state_dim, action_dim)\n","\n","    def select_action(self, state, noise_scale):\n","        action = self.actor.apply(self.actor_params, state)\n","        action = action + noise_scale * np.random.randn(self.action_dim)\n","        return np.clip(action, -1, 1)\n","\n","    def update(self):\n","        if len(self.replay_buffer.buffer) < self.batch_size:\n","            return\n","\n","        states, actions, rewards, next_states, dones = self.replay_buffer.sample(self.batch_size)\n","\n","        # Update Critic\n","        next_actions = self.target_actor.apply(self.target_actor_params, next_states)\n","        target_q_values = self.target_critic.apply(self.target_critic_params, next_states, next_actions)\n","        y = rewards + self.gamma * (1 - dones) * target_q_values.squeeze()\n","        y = y[:, None]\n","\n","        def critic_loss_fn(critic_params):\n","            q_values = self.critic.apply(critic_params, states, actions)\n","            loss = jnp.mean((q_values - y) ** 2)\n","            return loss\n","\n","        grad_fn = jax.value_and_grad(critic_loss_fn)\n","        loss, grads = grad_fn(self.critic_params)\n","        updates, self.critic_opt_state = self.critic_optimizer.update(grads, self.critic_opt_state)\n","        self.critic_params = optax.apply_updates(self.critic_params, updates)\n","\n","        # Update Actor\n","        def actor_loss_fn(actor_params):\n","            actions = self.actor.apply(actor_params, states)\n","            q_values = self.critic.apply(self.critic_params, states, actions)\n","            loss = -jnp.mean(q_values)\n","            return loss\n","\n","        grad_fn = jax.value_and_grad(actor_loss_fn)\n","        loss, grads = grad_fn(self.actor_params)\n","        updates, self.actor_opt_state = self.actor_optimizer.update(grads, self.actor_opt_state)\n","        self.actor_params = optax.apply_updates(self.actor_params, updates)\n","\n","        # Update Target Networks\n","        self.target_actor_params = jax.tree_multimap(lambda x, y: x * (1 - self.tau) + y * self.tau,\n","                                                     self.target_actor_params, self.actor_params)\n","        self.target_critic_params = jax.tree_multimap(lambda x, y: x * (1 - self.tau) + y * self.tau,\n","                                                      self.target_critic_params, self.critic_params)\n","\n","# 에이전트 학습 및 평가\n","batch_size = 32  # 병렬로 처리할 환경의 수\n","env, reset_fn, step_fn = create_env('ant', batch_size=batch_size)\n","\n","state_dim = env.observation_size\n","action_dim = env.action_size\n","\n","agent = DDPGAgent(state_dim, action_dim, actor_lr=1e-3, critic_lr=1e-3, gamma=0.99, tau=0.005, buffer_size=100000, batch_size=64)\n","\n","num_episodes = 500\n","log_interval = 10  # 로그를 출력할 에피소드 간격\n","\n","for episode in range(num_episodes):\n","    keys = jax.random.split(jax.random.PRNGKey(episode), batch_size)\n","    states = reset_fn(keys)\n","    total_rewards = np.zeros(batch_size)\n","    dones = np.zeros(batch_size, dtype=bool)\n","\n","    while not np.all(dones):\n","        # State 객체에서 상태 배열을 추출\n","        states = states.obs\n","        actions = jax.vmap(agent.select_action, in_axes=(0, None))(states, 0.1)\n","        next_states, rewards, dones, _ = step_fn(states, actions)\n","        # 다음 상태에서도 상태 배열을 추출\n","        next_states = next_states.obs\n","        for i in range(batch_size):\n","            agent.replay_buffer.add(states[i], actions[i], rewards[i], next_states[i], dones[i])\n","        agent.update()\n","        states = next_states\n","        total_rewards += rewards * (~dones)\n","\n","    if episode % log_interval == 0:\n","        print(f\"Episode: {episode}, Average Total Reward: {np.mean(total_rewards)}\")\n","\n","# 학습 후 에이전트의 동작 시각화\n","def visualize_agent(agent, env):\n","    state = env.reset(rng=jax.random.PRNGKey(seed=0))\n","    done = False\n","    frames = []\n","\n","    while not done:\n","        state = state.obs  # 상태 배열을 추출\n","        action = agent.select_action(state, noise_scale=0)\n","        next_state, reward, done, _ = env.step(action)\n","        next_state = next_state.obs  # 상태 배열을 추출\n","        frames.append(env.render())\n","        state = next_state\n","\n","    return html.render(frames)\n","\n","# 환경의 병렬 처리 비활성화\n","env = create('ant')\n","HTML(visualize_agent(agent, env))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FshFWM2m1Z3j","executionInfo":{"status":"error","timestamp":1715836665862,"user_tz":-540,"elapsed":2478,"user":{"displayName":"이건영","userId":"04018543955246161192"}},"outputId":"1b18c0c3-ef0b-4d47-f23d-227dcd6c8b40"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["JAX Devices: [cuda(id=0)]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"BatchTracer has no attribute info","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ShapedArray' object has no attribute 'info'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7c98248d7d37>\u001b[0m in \u001b[0;36m<cell line: 145>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# 다음 상태에서도 상태 배열을 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/brax/envs/wrappers/training.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'steps'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m       \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m       raise AttributeError(\n\u001b[0m\u001b[1;32m    792\u001b[0m           \u001b[0;34mf\"{self.__class__.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m       ) from err\n","\u001b[0;31mAttributeError\u001b[0m: BatchTracer has no attribute info"]}]}]}